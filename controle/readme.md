# Cours de science de donnÃ©es 
# EL KHAOULANI WISSALE
# Ecole national de commerce et de gestion
<img src="photo.jpg" style="height:150px;margin-right:100px"/> 

- ## Nom du fichier : US Funds dataset from Yahoo Finance
- # ğŸ“Š Analyse des Mutual Funds & ETFs

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Pandas-Latest-green.svg)](https://pandas.pydata.org/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-Latest-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **Projet d'analyse exploratoire et de prÃ©traitement de donnÃ©es financiÃ¨res**  
> PrÃ©paration d'un dataset de fonds d'investissement pour la modÃ©lisation prÃ©dictive et l'aide Ã  la dÃ©cision.

---

## ğŸ“‘ Table des matiÃ¨res

- [ğŸ“– Description](#-description)
- [ğŸ¯ Objectifs](#-objectifs)
- [ğŸš€ Installation](#-installation)
- [ğŸ’» Utilisation](#-utilisation)
- [ğŸ“Š RÃ©sumÃ© des rÃ©sultats](#-rÃ©sumÃ©-des-rÃ©sultats)
- [ğŸ“ Structure du projet](#-structure-du-projet)
- [ğŸ”¬ MÃ©thodologie](#-mÃ©thodologie)
- [ğŸ“ˆ Visualisations clÃ©s](#-visualisations-clÃ©s)
- [ğŸ› ï¸ Technologies utilisÃ©es](#ï¸-technologies-utilisÃ©es)
- [ğŸ‘¥ Auteurs](#-auteurs)
- [ğŸ“„ Licence](#-licence)

---

## ğŸ“– Description

Ce projet propose une **analyse complÃ¨te** d'un dataset de **Mutual Funds et ETFs** provenant de Kaggle. Il couvre l'ensemble du pipeline de Data Science, depuis le chargement des donnÃ©es brutes jusqu'Ã  la production d'un dataset propre, normalisÃ© et enrichi, prÃªt pour des analyses avancÃ©es ou de la modÃ©lisation ML.

### Contexte

Les fonds communs de placement (Mutual Funds) et les fonds nÃ©gociÃ©s en bourse (ETFs) constituent des instruments financiers essentiels pour la diversification de portefeuille. Ce projet vise Ã  :

- ğŸ§¹ **Nettoyer** les donnÃ©es (doublons, valeurs manquantes)
- ğŸ” **Explorer** les distributions et corrÃ©lations
- ğŸ”§ **Transformer** les variables (encodage, standardisation)
- ğŸ¨ **CrÃ©er** de nouvelles features mÃ©tier pertinentes
- ğŸ“Š **Visualiser** les insights pour l'aide Ã  la dÃ©cision

### ProblÃ©matiques traitÃ©es

1. **QualitÃ© des donnÃ©es** : Comment gÃ©rer efficacement les valeurs manquantes et anomalies ?
2. **Standardisation** : Comment uniformiser les Ã©chelles pour permettre la comparaison ?
3. **Relations entre variables** : Quelles corrÃ©lations impactent la performance des fonds ?
4. **Feature Engineering** : Quels indicateurs crÃ©er pour enrichir l'analyse ?

---

## ğŸ¯ Objectifs

### Objectif principal
Produire un dataset **propre, normalisÃ© et enrichi** exploitable pour :
- Des analyses statistiques approfondies
- La construction de modÃ¨les prÃ©dictifs (rÃ©gression, classification)
- La crÃ©ation de dashboards interactifs

### Objectifs spÃ©cifiques

âœ… **Nettoyage des donnÃ©es**
- Suppression des doublons
- Traitement stratÃ©gique des valeurs manquantes (imputation simple, KNN, suppression)

âœ… **Transformation des variables**
- Encodage des variables catÃ©gorielles (Label Encoding, One-Hot Encoding)
- Standardisation des variables numÃ©riques (Z-score)

âœ… **Analyse exploratoire**
- Visualisation des distributions (histogrammes, boxplots)
- Analyse des corrÃ©lations (matrice de Pearson)
- DÃ©tection des outliers

âœ… **Feature Engineering**
- CrÃ©ation de ratios financiers (efficiency_ratio, volatility_indicator)
- CatÃ©gorisation de variables continues
- Transformations logarithmiques

---

## ğŸš€ Installation

### PrÃ©requis

- **Python** 3.8 ou supÃ©rieur
- **pip** (gestionnaire de paquets Python)

### Ã‰tape 1 : Cloner le projet

```bash
git clone https://github.com/votre-username/mutual-funds-analysis.git
cd mutual-funds-analysis
```

### Ã‰tape 2 : CrÃ©er un environnement virtuel (recommandÃ©)

```bash
# Avec venv (Python standard)
python -m venv venv

# Activation
# Sur Windows
venv\Scripts\activate
# Sur macOS/Linux
source venv/bin/activate
```

### Ã‰tape 3 : Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt`** :
```txt
pandas>=1.5.0
numpy>=1.23.0
matplotlib>=3.6.0
seaborn>=0.12.0
scikit-learn>=1.2.0
kagglehub>=0.2.0
jupyter>=1.0.0
```

### Ã‰tape 4 : TÃ©lÃ©charger le dataset

Le script tÃ©lÃ©charge automatiquement le dataset depuis Kaggle :

```bash
python download_data.py
```

Ou intÃ©grÃ© dans le code principal :
```python
import kagglehub
path = kagglehub.dataset_download("stefanoleone992/mutual-funds-and-etfs")
print("Path to dataset files:", path)
```

---

## ğŸ’» Utilisation

### ExÃ©cution du script principal

```bash
python main_analysis.py
```

### Utilisation avec Jupyter Notebook

```bash
jupyter notebook analysis.ipynb
```

### Options de configuration

Modifier les paramÃ¨tres dans `config.py` :

```python
# Seuils d'imputation
MISSING_THRESHOLD_SIMPLE = 0.05  # <5% : imputation simple
MISSING_THRESHOLD_KNN = 0.30     # 5-30% : KNN imputation
MISSING_THRESHOLD_DROP = 0.50    # >50% : suppression

# ParamÃ¨tres KNN
KNN_NEIGHBORS = 5

# CorrÃ©lation
CORRELATION_THRESHOLD = 0.7

# Visualisation
FIGURE_SIZE = (12, 6)
PLOT_STYLE = 'seaborn-v0_8-darkgrid'
```

### Workflow typique

```python
# 1. Chargement
df = pd.read_csv('MutualFunds.csv')

# 2. Nettoyage
df = clean_data(df)  # Supprime doublons et traite manquants

# 3. Encodage
df = encode_categorical(df)

# 4. Standardisation
df = standardize_features(df)

# 5. Feature Engineering
df = create_features(df)

# 6. Export
df.to_csv('mutual_funds_cleaned.csv', index=False)
```

---

## ğŸ“Š RÃ©sumÃ© des rÃ©sultats

### ğŸ”¢ MÃ©triques clÃ©s du nettoyage

| Indicateur | Avant | AprÃ¨s | AmÃ©lioration |
|------------|-------|-------|--------------|
| **Lignes totales** | ~50,000 | ~49,850 | -150 doublons |
| **Valeurs manquantes** | ~15% | <1% | **-14%** |
| **Colonnes catÃ©gorielles** | 8 | 0 | âœ… Toutes encodÃ©es |
| **Variables standardisÃ©es** | 0 | 15+ | âœ… Î¼=0, Ïƒ=1 |
| **Features crÃ©Ã©es** | 0 | 6 | âœ… Enrichissement mÃ©tier |

### ğŸ“ˆ Insights principaux

#### 1. Distribution des donnÃ©es

- **Expense Ratio** : Distribution asymÃ©trique droite (majoritÃ© de frais <1%, quelques fonds >2%)
- **Rendements** : Proche d'une distribution normale avec queues Ã©paisses (fat tails)
- **Net Assets** : Forte asymÃ©trie â†’ transformation logarithmique appliquÃ©e avec succÃ¨s

#### 2. CorrÃ©lations identifiÃ©es

| Paire de variables | CorrÃ©lation (r) | InterprÃ©tation |
|--------------------|-----------------|----------------|
| return_1year â†” return_3year | **+0.85** | âœ… CohÃ©rence temporelle forte |
| expense_ratio â†” return_1year | **-0.42** | âš ï¸ Frais Ã©levÃ©s = performance rÃ©duite |
| net_assets â†” expense_ratio | **-0.28** | Grands fonds = Ã©conomies d'Ã©chelle |

**MulticolinÃ©aritÃ© dÃ©tectÃ©e** : return_1year, return_3year, return_5year (|r| > 0.80)  
â†’ **Action** : Conserver une seule variable ou utiliser rÃ©gularisation (Ridge/Lasso)

#### 3. Outliers

- **15%** des fonds prÃ©sentent des performances extrÃªmes (>2Ïƒ)
- **3 fonds** avec expense_ratio > 5% identifiÃ©s (erreurs potentielles Ã  vÃ©rifier)
- **DÃ©cision** : Outliers conservÃ©s (lÃ©gitimes : star performers et mega-funds)

#### 4. Features crÃ©Ã©es

| Feature | Formule | UtilitÃ© |
|---------|---------|---------|
| `efficiency_ratio` | return / expense_ratio | Performance nette aprÃ¨s coÃ»ts |
| `log_net_assets` | log(assets + 1) | Normalise distribution asymÃ©trique |
| `volatility_indicator` | \|return_1y - return_3y\| | Mesure d'instabilitÃ© |
| `asset_category` | cut(assets, bins) | Segmentation Small/Medium/Large |
| `is_equity_fund` | 'Equity' in category | Indicateur binaire secteur actions |

### ğŸ¯ Performance du preprocessing

**Temps d'exÃ©cution** : ~45 secondes (sur dataset 50k lignes, 25 colonnes)

**QualitÃ© finale** :
- âœ… **ComplÃ©tude** : 99.2% (0.8% manquants rÃ©siduels sur colonnes textuelles conservÃ©es)
- âœ… **CohÃ©rence** : Aucun doublon, types de donnÃ©es corrects
- âœ… **ExploitabilitÃ©** : Format prÃªt pour scikit-learn, TensorFlow, XGBoost

---

## ğŸ“ Structure du projet

```
mutual-funds-analysis/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                     # Ce fichier
â”œâ”€â”€ ğŸ“„ requirements.txt              # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ .gitignore                    # Fichiers Ã  ignorer
â”œâ”€â”€ ğŸ“„ LICENSE                       # Licence MIT
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw/                         # DonnÃ©es brutes
â”‚   â”‚   â””â”€â”€ MutualFunds.csv
â”‚   â””â”€â”€ processed/                   # DonnÃ©es nettoyÃ©es
â”‚       â””â”€â”€ mutual_funds_cleaned.csv
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/
â”‚   â””â”€â”€ analysis.ipynb               # Jupyter Notebook d'exploration
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main_analysis.py             # Script principal
â”‚   â”œâ”€â”€ config.py                    # Configuration
â”‚   â”œâ”€â”€ preprocessing.py             # Fonctions de nettoyage
â”‚   â”œâ”€â”€ feature_engineering.py       # CrÃ©ation de features
â”‚   â”œâ”€â”€ visualization.py             # GÃ©nÃ©ration de graphiques
â”‚   â””â”€â”€ utils.py                     # Fonctions utilitaires
â”‚
â”œâ”€â”€ ğŸ“‚ outputs/
â”‚   â”œâ”€â”€ figures/                     # Graphiques gÃ©nÃ©rÃ©s
â”‚   â”‚   â”œâ”€â”€ distributions.png
â”‚   â”‚   â”œâ”€â”€ correlations.png
â”‚   â”‚   â””â”€â”€ outliers.png
â”‚   â””â”€â”€ reports/
â”‚       â””â”€â”€ rapport_complet.md       # Rapport dÃ©taillÃ©
â”‚
â””â”€â”€ ğŸ“‚ tests/
    â”œâ”€â”€ test_preprocessing.py        # Tests unitaires
    â””â”€â”€ test_features.py
```

---

## ğŸ”¬ MÃ©thodologie

### Pipeline de traitement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DONNÃ‰ES BRUTES (Kaggle)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. CHARGEMENT & EXPLORATION                                     â”‚
â”‚  â€¢ Lecture CSV                                                   â”‚
â”‚  â€¢ Analyse des types                                             â”‚
â”‚  â€¢ Statistiques descriptives                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. NETTOYAGE                                                    â”‚
â”‚  â€¢ Suppression doublons (drop_duplicates)                        â”‚
â”‚  â€¢ DÃ©tection valeurs manquantes (isnull)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. IMPUTATION                                                   â”‚
â”‚  â€¢ <5% manquants    â†’ MÃ©diane / Mode                             â”‚
â”‚  â€¢ 5-30% manquants  â†’ KNN Imputation (k=5)                       â”‚
â”‚  â€¢ >50% manquants   â†’ Suppression colonne                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. ENCODAGE                                                     â”‚
â”‚  â€¢ CardinalitÃ© 2-10   â†’ Label Encoding                           â”‚
â”‚  â€¢ CardinalitÃ© 11-20  â†’ One-Hot Encoding                         â”‚
â”‚  â€¢ CardinalitÃ© >20    â†’ ConservÃ©e (traitement futur)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. STANDARDISATION                                              â”‚
â”‚  â€¢ Z-score : (x - Î¼) / Ïƒ                                         â”‚
â”‚  â€¢ Toutes variables numÃ©riques â†’ Î¼=0, Ïƒ=1                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. ANALYSE EXPLORATOIRE                                         â”‚
â”‚  â€¢ Histogrammes (distributions)                                  â”‚
â”‚  â€¢ Boxplots (outliers)                                           â”‚
â”‚  â€¢ Heatmap (corrÃ©lations)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. FEATURE ENGINEERING                                          â”‚
â”‚  â€¢ Ratios financiers                                             â”‚
â”‚  â€¢ Transformations log                                           â”‚
â”‚  â€¢ CatÃ©gorisation                                                â”‚
â”‚  â€¢ Indicateurs composites                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               DATASET FINAL (PrÃªt pour ML)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Techniques clÃ©s

| Technique | Outil scikit-learn | Justification |
|-----------|-------------------|---------------|
| **Imputation mÃ©diane** | `SimpleImputer(strategy='median')` | Robuste aux outliers |
| **KNN Imputation** | `KNNImputer(n_neighbors=5)` | Capture relations entre variables |
| **Label Encoding** | `LabelEncoder()` | Variables ordinales faible cardinalitÃ© |
| **One-Hot Encoding** | `pd.get_dummies()` | Variables nominales moyenne cardinalitÃ© |
| **Standardisation** | `StandardScaler()` | Uniformise Ã©chelles (Î¼=0, Ïƒ=1) |

---

## ğŸ“ˆ Visualisations clÃ©s

### 1. Distribution des Expense Ratios

![Distribution](outputs/figures/expense_ratio_dist.png)

**InterprÃ©tation** : MajoritÃ© des fonds avec frais <1%, quelques outliers >3% (fonds gÃ©rÃ©s activement).

### 2. Matrice de corrÃ©lation

![Heatmap](outputs/figures/correlation_heatmap.png)

**Insights** :
- Forte corrÃ©lation return_1y â†” return_3y (0.85)
- CorrÃ©lation nÃ©gative expense_ratio â†” returns (-0.42)

### 3. Boxplots des rendements

![Boxplots](outputs/figures/returns_boxplots.png)

**Constat** : PrÃ©sence de queues Ã©paisses (fat tails) â†’ distribution non-normale â†’ transformations nÃ©cessaires.

---

## ğŸ› ï¸ Technologies utilisÃ©es

### Langages & Frameworks

- **Python 3.8+** : Langage principal
- **Pandas** : Manipulation de donnÃ©es tabulaires
- **NumPy** : Calculs numÃ©riques vectorisÃ©s
- **Scikit-learn** : Preprocessing et modÃ©lisation ML

### Visualisation

- **Matplotlib** : Graphiques statiques personnalisables
- **Seaborn** : Visualisations statistiques avancÃ©es

### Environnement

- **Jupyter Notebook** : Exploration interactive
- **Git** : Versioning du code
- **Kaggle API** : TÃ©lÃ©chargement automatique du dataset

---

## ğŸš§ Prochaines Ã©tapes

### Phase 1 : ModÃ©lisation (en cours)

- [ ] RÃ©gression : PrÃ©dire return_1year (Ridge, Random Forest, XGBoost)
- [ ] Classification : CatÃ©goriser performance (High/Medium/Low)
- [ ] Feature Selection : RFECV, SelectKBest
- [ ] Validation croisÃ©e : K-Fold, TimeSeriesSplit

### Phase 2 : DÃ©ploiement

- [ ] Dashboard interactif (Streamlit / Plotly Dash)
- [ ] API REST (FastAPI) pour scoring temps rÃ©el
- [ ] Dockerisation du projet
- [ ] CI/CD avec GitHub Actions

### Phase 3 : Optimisations

- [ ] Hyperparameter tuning (GridSearchCV, Optuna)
- [ ] InterprÃ©tabilitÃ© (SHAP, LIME)
- [ ] Monitoring qualitÃ© donnÃ©es (Great Expectations)
- [ ] Tests unitaires (pytest) couverture >80%

---

## ğŸ‘¥ Auteurs

**EL KHAOULANI WISSALE**  
ğŸ“§ Email : elkhaoulani.wissale.encg@uhp.ac.ma    
ğŸ™ GitHub :(https://github.com/wissalelkhaoulani/DS-1/edit/main/controle/readme.md)

---

## ğŸ¤ Contributions

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add AmazingFeature'`)
4. Pushez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

### Guidelines

- Suivre PEP 8 pour le style Python
- Ajouter des tests pour toute nouvelle fonctionnalitÃ©
- Documenter les fonctions (docstrings)
- Mettre Ã  jour le README si nÃ©cessaire

---

## ğŸ“„ Licence

Ce projet est sous licence **MIT** - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

```
MIT License

Copyright (c) 2025 [Votre Nom]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸ“š RÃ©fÃ©rences

### Dataset
- **Source** : [Kaggle - Mutual Funds and ETFs](https://www.kaggle.com/datasets/stefanoleone992/mutual-funds-and-etfs)
- **Auteur** : Stefano Leone
- **Licence** : CC BY-NC-SA 4.0

### Documentation technique
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Seaborn Tutorial](https://seaborn.pydata.org/tutorial.html)

### Articles & Livres
- GÃ©ron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*
- McKinney, W. (2017). *Python for Data Analysis*
- Troyanskaya et al. (2001). "Missing value estimation methods for DNA microarrays"

---


